[["index.html", "16s rRNA analysis workshop 1 Introduction 1.1 Workshop Schedule 1.2 Important links", " 16s rRNA analysis workshop Hena R. Ramay 2021-11-02 1 Introduction Our intention is to develop workshop material as we go along. For each day of the workshop, the basic material will be uploaded and more details will be added based on your questions and problems we encounter. So please ask as many questions are you can to help us in making this workshop better!! 1.1 Workshop Schedule We will try to cover the following material in the course: Day1 9:00 - 9:45 am Introductions and a presentation of the basic concepts 9:45 - 10:30 am CutAdapt- how remove primers 10:30 - 10:45 am Break 10:45 - 12 pm Installations of the required packages and data download 12 - 1 pm Lunch break 1 - 3 pm Reading data in and inspecting read quality Day2 9:30 -10:30 am Filter and trim + learn error rates + Sample inference + Merge samples 10:30 - 10:45 am Break 10:45 - 12 Generate sequence table and remove Chimeras 12 - 1 pm Lunch break 1 - 2 pm Taxonomy explanation + assign your sequences. If time permits, make a phyloseq object 2 - 4 pm on wards we will use a real world dataset to re-do what we have learned here 1.2 Important links DADA2 Tutorial : link Day One presentation : link Day One dataset : link Project dataset : link "],["basic-information.html", "2 Basic Information 2.1 What are we trying to achieve 2.2 Basics &amp; Background", " 2 Basic Information We are very excited to teach this workshop and share what we know with you all ! So lets start by talking about the very basics: 2.1 What are we trying to achieve Our goal is very similar to gathering data on a city neighbourhood to find out who lives there, how the demographic changes over time or in case of a drastic event. We can gather more information by asking about neighbours, quality of life etc. Similarly when we are looking at microbial communities our first question is who is there, how abundant and how their presence changes over time or when conditions change. We can also ask questions like how the microbiomes are interacting with each other (metabolites). For the scope of this workshop we will stick to the simple questions: who and how much? 2.2 Basics &amp; Background Here is the link to the lecture we will start with today: workshop Key points are: Think of a hypothesis before doing an experiment Spend time on experiment design. Sample size, 16s region to amplify etc Talk to a bioinformatician Think about the depth of sequencing if you want to capture the less abundant taxa Add negative control to account for contamination Thoughtful data analysis is critical for successful identification of microbes “If you torture the data long enough, it will confess.”- Ronald Coase, Economist "],["primer-removal.html", "3 Primer Removal 3.1 CutAdapt", " 3 Primer Removal There are multiple ways in which you can remove primers sequences from your fastq files. CutAdapt and trimmomatic are two widely used tools for short-read data. DADA2 package has its own removePrimers sequence function which is recommended for PacBio data. 3.1 CutAdapt The first step that everyone performs before doing an analysis is data cleaning. Data cleaning can mean multiple things in this context: primer removal, quality trimming, removing very short sequences etc. Remember inconsistent and incorrect data leads to false conclusions. In short, garbage in, garbage out applies to all data. The first step that we will do with amplicon data is check which 16s rRNA gene region was sequenced, find the primer that were used and remove them. For this purpose there are a few software available like, cutAdapt, Trimmomatic, skewer. For the purpose of this workshop we will use cutAdapt. Cutadapt finds and removes adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads. It also alows you to perform quality trimming on your reads. 3.1.1 Primer removal for paired end reads cutadapt -a ADAPTER_FWD -A ADAPTER_REV -o out.1.fastq -p out.2.fastq reads.1.fastq reads.2.fastq Here, the input reads are in reads.1.fastq and reads.2.fastq, and the result will be written to out.1.fastq and out.2.fastq. In paired-end mode, the options -a, -b, -g and -u that also exist in single-end mode are applied to the forward reads only. To modify the reverse read, these options have uppercase versions -A, -B, -G and -U that work just like their counterparts. In the example above, ADAPTER_FWD will therefore be trimmed from the forward reads and ADAPTER_REV from the reverse reads. Single-end/R1 option Corresponding option for R2 –adapter, -a -A –front, -g -G –anywhere, -b -B –cut, -u -U –output, -o –paired-output, -p In paired-end mode, Cutadapt checks whether the input files are properly paired. An error is raised if one of the files contains more reads than the other or if the read names in the two files do not match. The read name comparison ignores a trailing /1 or /2 to allow processing some old Illumina paired-end files. Cutadapt supports compressed input and output files. Whether an input file needs to be decompressed or an output file needs to be compressed is detected automatically by inspecting the file name: For example, if it ends in .gz, then gzip compression is assumed 3.1.2 Quality trimming cutadapt -q 15,10 -o out.1.fastq -p out.2.fastq reads.1.fastq reads.2.fastq -q 15,10 3.1.3 Call cutAdapt from R Follow this link to see how you can call cutAdapt from within R https://benjjneb.github.io/dada2/ITS_workflow.html "],["dada2.html", "4 DADA2 4.1 DADA2 pipeline (v1.2) 4.2 Some tips:", " 4 DADA2 4.1 DADA2 pipeline (v1.2) From now on, we will be working on the DADA2 package version 1.12. DADA2 has great documentation and an excellent tutorial online.Please go to the following link http://benjjneb.github.io/dada2/tutorial.html All the notes from now on are my additional comments to help you follow the pipeline: 4.1.1 Data for the tutorial The data to use for the tutorial can be downloaded from here 4.1.2 Getting ready ( load packages and get file list) Functions that we will be using here are : list.files() sort() strsplit() basename() sapply() 4.1.3 Inspect read quality profiles Read in files library(dada2); ## Loading required package: Rcpp library(limma) path &lt;- &quot;MiSeq_SOP/&quot; list.files(path) ## [1] &quot;F3D0_S188_L001_R1_001.fastq&quot; &quot;F3D0_S188_L001_R2_001.fastq&quot; ## [3] &quot;F3D1_S189_L001_R1_001.fastq&quot; &quot;F3D1_S189_L001_R2_001.fastq&quot; ## [5] &quot;F3D141_S207_L001_R1_001.fastq&quot; &quot;F3D141_S207_L001_R2_001.fastq&quot; ## [7] &quot;F3D142_S208_L001_R1_001.fastq&quot; &quot;F3D142_S208_L001_R2_001.fastq&quot; ## [9] &quot;F3D143_S209_L001_R1_001.fastq&quot; &quot;F3D143_S209_L001_R2_001.fastq&quot; ## [11] &quot;F3D144_S210_L001_R1_001.fastq&quot; &quot;F3D144_S210_L001_R2_001.fastq&quot; ## [13] &quot;F3D145_S211_L001_R1_001.fastq&quot; &quot;F3D145_S211_L001_R2_001.fastq&quot; ## [15] &quot;F3D146_S212_L001_R1_001.fastq&quot; &quot;F3D146_S212_L001_R2_001.fastq&quot; ## [17] &quot;F3D147_S213_L001_R1_001.fastq&quot; &quot;F3D147_S213_L001_R2_001.fastq&quot; ## [19] &quot;F3D148_S214_L001_R1_001.fastq&quot; &quot;F3D148_S214_L001_R2_001.fastq&quot; ## [21] &quot;F3D149_S215_L001_R1_001.fastq&quot; &quot;F3D149_S215_L001_R2_001.fastq&quot; ## [23] &quot;F3D150_S216_L001_R1_001.fastq&quot; &quot;F3D150_S216_L001_R2_001.fastq&quot; ## [25] &quot;F3D2_S190_L001_R1_001.fastq&quot; &quot;F3D2_S190_L001_R2_001.fastq&quot; ## [27] &quot;F3D3_S191_L001_R1_001.fastq&quot; &quot;F3D3_S191_L001_R2_001.fastq&quot; ## [29] &quot;F3D5_S193_L001_R1_001.fastq&quot; &quot;F3D5_S193_L001_R2_001.fastq&quot; ## [31] &quot;F3D6_S194_L001_R1_001.fastq&quot; &quot;F3D6_S194_L001_R2_001.fastq&quot; ## [33] &quot;F3D7_S195_L001_R1_001.fastq&quot; &quot;F3D7_S195_L001_R2_001.fastq&quot; ## [35] &quot;F3D8_S196_L001_R1_001.fastq&quot; &quot;F3D8_S196_L001_R2_001.fastq&quot; ## [37] &quot;F3D9_S197_L001_R1_001.fastq&quot; &quot;F3D9_S197_L001_R2_001.fastq&quot; ## [39] &quot;filtered&quot; &quot;HMP_MOCK.v35.fasta&quot; ## [41] &quot;Mock_S280_L001_R1_001.fastq&quot; &quot;Mock_S280_L001_R2_001.fastq&quot; ## [43] &quot;mouse.dpw.metadata&quot; &quot;mouse.time.design&quot; ## [45] &quot;stability.batch&quot; &quot;stability.files&quot; # Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq fnFs &lt;- sort(list.files(path, pattern=&quot;_R1_001.fastq&quot;, full.names = TRUE)) fnRs &lt;- sort(list.files(path, pattern=&quot;_R2_001.fastq&quot;, full.names = TRUE)) # Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq tmp&lt;-strsplit(basename(fnFs), &quot;_&quot;) # As tmp is a list of vectors, we will have to use sapply function to get the first position out from each vector. The symbol &#39;[&#39; tells sapplly function that it is a vector and 1 specifies the vector index samples.names&lt;-sapply(tmp,&#39;[&#39;,1) 4.1.4 Lets make plots to look at the quality for multiple files plotQualityProfile(fnFs[1:2]) ## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will ## replace the existing scale. joint_fnames&lt;-c(rbind(fnFs,fnRs)) plotQualityProfile(joint_fnames) ## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will ## replace the existing scale. if there are too many files, use arrangegrob. See here here for details For the rest of the DADA2 pipelien please visit 4.2 Some tips: At every step check how many reads are getting filtered. This is very important to make sure that you are not losing too much data. If in the filtering step you are losing too many reads, relax the maxEE from 2 to 3 or more. Also check the length that you are truncating at. If you are using cutAdapt for quality trimming, you don’t have to use truncation in filterandtrim function of DADA2 Always keep in mind the overlap length for your region of interest. see the figure below for calculation: If you lose too many sequences to chimera removal, please check that the primers are removed properly. "],["day-two.html", "5 Day Two 5.1 Main concepts to be discussed: 5.2 Alpha &amp; beta Diversity", " 5 Day Two 5.1 Main concepts to be discussed: Finish dada2 pipeline Assign Taxonomy Intro to Phyolseq package Create a Phylum level bar plots Alpha diversity plots Beta diversity plots Once we are finished using the dada2 package, we will have a sequence table and taxonomy table. Lets look at the metadata files we have to get more information about these samples. library(ggplot2) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union time_info&lt;-read.delim(&quot;~/projects/16sanalysis_workshop/workshoptutorial/MiSeq_SOP/mouse.time.design&quot;,sep = &quot;\\t&quot;) dpw_info&lt;-read.delim(&quot;~/projects/16sanalysis_workshop/workshoptutorial/MiSeq_SOP/mouse.dpw.metadata&quot;,sep = &quot;\\t&quot;) sample_info&lt;-left_join(time_info,dpw_info,by=&quot;group&quot;) rownames(sample_info)&lt;- sample_info$group sample_info ## group time dpw ## F3D0 F3D0 Early 0 ## F3D1 F3D1 Early 1 ## F3D141 F3D141 Late 141 ## F3D142 F3D142 Late 142 ## F3D143 F3D143 Late 143 ## F3D144 F3D144 Late 144 ## F3D145 F3D145 Late 145 ## F3D146 F3D146 Late 146 ## F3D147 F3D147 Late 147 ## F3D148 F3D148 Late 148 ## F3D149 F3D149 Late 149 ## F3D150 F3D150 Late 150 ## F3D2 F3D2 Early 2 ## F3D3 F3D3 Early 3 ## F3D5 F3D5 Early 5 ## F3D6 F3D6 Early 6 ## F3D7 F3D7 Early 7 ## F3D8 F3D8 Early 8 ## F3D9 F3D9 Early 9 Lets make a phyloseq object Now that we have sample_info lets try to make a phyloseq object out of this library(phyloseq) taxa&lt;-readRDS(&quot;~/projects/16sanalysis_workshop/workshoptutorial/output/taxa.rds&quot;) seq&lt;-readRDS(&quot;~/projects/16sanalysis_workshop/workshoptutorial/output/seq.rds&quot;) ps &lt;- phyloseq(otu_table(seq,taxa_are_rows = F), sample_data(sample_info), tax_table(taxa)) ps ## phyloseq-class experiment-level object ## otu_table() OTU Table: [ 234 taxa and 19 samples ] ## sample_data() Sample Data: [ 19 samples by 3 sample variables ] ## tax_table() Taxonomy Table: [ 234 taxa by 7 taxonomic ranks ] You can see that this object has an OTU table(ASV table), sample data and tax_table. You can use functions tax_table(), sample_data() and otu_table() to access the data. Take a look at: subset_samples() subset_taxa() tax_glom() sample_sums() prune_samples() transform_sample_counts() psmelt() ps2&lt;-tax_glom(ps,taxrank = &quot;Phylum&quot;) ps2 = transform_sample_counts(ps2, function(x) x/sum(x)) pmelt&lt;-psmelt(ps2) %&gt;% arrange(desc(Abundance)) cutoff&lt;-0.005 pmelt_filt&lt;-pmelt %&gt;% group_by(Phylum,time) %&gt;% filter(sum(Abundance) &gt;cutoff) ggplot(pmelt_filt,aes(x=Sample,y=Abundance,color=Phylum,fill=Phylum)) +geom_bar(stat = &quot;identity&quot;) pmelt_filt %&gt;% group_by(time,Phylum) %&gt;% summarise(mean_Abundance=mean(Abundance)) %&gt;% ggplot(.,aes(x=time,y=mean_Abundance,fill=Phylum)) +geom_bar(stat=&quot;identity&quot;) ## `summarise()` has grouped output by &#39;time&#39;. You can override using the `.groups` argument. Figure out how to change the colors to custom colors!! pmelt_filt %&gt;% group_by(time,Phylum) %&gt;% summarise(mean=mean(Abundance)) ## `summarise()` has grouped output by &#39;time&#39;. You can override using the `.groups` argument. ## # A tibble: 12 x 3 ## # Groups: time [2] ## time Phylum mean ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 Early Actinobacteria 0.00133 ## 2 Early Bacteroidetes 0.592 ## 3 Early Cyanobacteria 0.000594 ## 4 Early Firmicutes 0.378 ## 5 Early Patescibacteria 0.00285 ## 6 Early Proteobacteria 0.00331 ## 7 Early Tenericutes 0.0218 ## 8 Late Actinobacteria 0.00472 ## 9 Late Bacteroidetes 0.716 ## 10 Late Firmicutes 0.269 ## 11 Late Patescibacteria 0.000993 ## 12 Late Tenericutes 0.00845 5.2 Alpha &amp; beta Diversity "],["project.html", "6 Project 6.1 Setup 6.2 Task 1 (Ignore this task) 6.3 Task 2 6.4 Task 3 6.5 Project solutions", " 6 Project 6.1 Setup Please download the raw data here. These samples are from a study looking at the effect of a prebiotic on the gut microbiota of children with type 1 diabetes. To invesigate this, the researchers took samples at three timepoints (baseline, 3 months, and 6 months) and sequenced the V3-V4 region of the 16S rRNA gene. 6.2 Task 1 (Ignore this task) The first step with all sequence data is to ensure the primers have been removed. The two most common tools to accomplish this are Cutadapt and Trimmomatic. Note: both of these tools can be used for quality trimming as well as primer removal but here we will perform the quality trimming in dada2 instead. 6.2.1 Cutadapt You can find the documentation for this tool here. These are the parameters that contain the primer sequences: -g : forward primer -G : reverse primer -a : reverse primer, reverse complement -A : forward primer, reverse complement For this dataset, these are the appropriate primers: -g TCGTCGGCAGCGTCAGATGTGTATAAGAGACAGCCTACGGGNGGCWGCAG -G GTCTCGTGGGCTCGGAGATGTGTATAAGAGACAGGACTACHVGGGTATCTAATCC -a GGATTAGATACCCBDGTAGTCCTGTCTCTTATACACATCTCCGAGCCCACGAGAC -A CTGCWGCCNCCCGTAGGCTGTCTCTTATACACATCTGACGCTGCCGACGA Here is an example of how to execute Cutadapt from the command line: cutadapt -g &lt;sequence&gt; -G &lt;sequence&gt; -a &lt;sequence&gt; -A &lt;sequence&gt; -o output_forward.fastq -p output_reverse.fastq input_forward.fastq input_reverse.fastq Note that you can also run cutadapt from within R. You can find instructions on how to do that here. 6.2.2 Trimmomatic You can find the documentation for this tool here. Instead of specifying forward and reverse reads, Trimmomatic takes a fasta file as input and searches the reads for all sequences in the files. When using Trimmomatic on paired-end reads, you will get four output files: forward and reverse reads that are still paired (reads for which both forward and reverse were kept) and forward and reverse reads that are unpaired. In general, the number of unpaired reads should be small and you can continue with your analysis without these. For this dataset, you can use this fasta. Here is an example of how to execute Trimmomatic from the command line: trimmomatic PE input_forward.fq.gz input_reverse.fq.gz output_forward_paired.fq.gz output_forward_unpaired.fq.gz output_reverse_paired.fq.gz output_reverse_unpaired.fq.gz ILLUMINACLIP:v3v4primers.fa:2:30:10:2:keepBothReads LEADING:0 TRAILING:0 MINLEN:0 6.2.3 Primers removed If you don’t care about using either of these tools and want to move on to the next step, you can find the sequences with the primers removed here. 6.3 Task 2 Use the dada2 pipeline to generate a table of ASVs and a taxonomy table. Plot quality profiles of the reads for all samples. Save these as pdf files. Try a couple of sets of filtering params and determine the best choice. Filter and trim the data and generate the quality plots again. Save these as well. Learn the error rates and visually inspect the estimated error rates. Infer samples. Merge paired reads. Construct sequence table. Remove chimeras. Track reads through the pipeline and ensure that no step of the analysis removed a large/unreasonable proportion of the reads. Assign taxonomy using the Silva databse. Save the ASV table and taxonomy table using the saveRDS() function. 6.4 Task 3 Use the phyloseq package to generate do some basic analysis. For this section you will need the project metadata files that you already downloaded Generate a histogram of the number of reads per sample. Does this look okay? Generate a table of alpha diversity measures (Shannon, Simspon, and Chao1) and use this table to plot alpha diversity by treatment and timepoint. Transform the data to relative abundances and remove ASVs that are only present in less than 5% of the samples. Perform a principal component analysis (PCoA) using the ordinate() function and distance = \"bray\". Plot beta diversity. Explore the composition of each sample by generating bar plots of the relative abundances at the level of phylum, family, and genus. For family and genus, plot only the top 10 most abundant taxa. 6.5 Project solutions 6.5.1 Task 2 - dada2 For this section, the solution closely resembles the code from the dada2 tutorial. The main challenge is to determine the appropriate filtering parameters. Here are the quality profiles for the forward and reverse reads for samples 01MP-1 and 03KW-1. You can see that the quality of the ends of the reverse reads are much worse than the forward reads. To help guide our parameter choice, here is a plot showing the percentage of reads that passed filtering as a produce of changing both the forward error rate and the reverse error rate. Based on this, we should choose an error rate of c(3,4) or something similar. Note that the truncation length used here was c(265,245). After filtering, we look the effect of the filtering on the quality profiles. Below are the before and after filtering quality profiles of the forward and reverse reads of sample 01MP-1. 6.5.2 Task 3 - phyloseq Following the dada2 pipeline, we will have a sequence table and a taxonomy table. "],["what-next.html", "7 What Next?", " 7 What Next? What you have learnt so far is just the beginging!! There is a lot more ot learn and do. For example, after looking at beta diversity, you can also look at differential abundance to see which taxa are different in each treatment group or over time. Most commonly used methods for doing this is deseq2 and a new one is corncob. Before using them, please read the papers carefully to know the limitations and correct usage of these pacakages. Some people also try to do functional analaysis with 16s data and for this PICRUST2 pacakge is usually used. "]]
