---
title: "16s rRNA analysis workshop"
author: "Hena R. Ramay"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "This tutorial covers workshop material for all three days"
---

# Introduction

Our intention is to develop workshop material as we go along. For each day of the workshop, the basic material will be uploaded and more details will be added based on your questions and problems we encounter. So please ask as many questions are you can to help us in making this workshop better!!

## Workshop Schedule

We will try to cover the following material in the course:

- Day1
  - 9:00 - 9:45 am Introductions and a presentation of the basic concepts
  - 9:45 - 10:30 am CutAdapt- how remove primers
  - 10:30 - 10:45 am Break
  - 10:45 - 12 pm Installations of the required packages and data download
  - 12 -  1 pm Lunch break
  - 1 - 3 pm Reading data in and inspecting read quality

- Day2
  - 9:30 -10:30 am Filter and trim + learn error rates + Sample inference + Merge samples
  - 10:30 - 10:45 am Break
  - 10:45 - 12 Generate sequence table and remove Chimeras
  - 12 -  1 pm Lunch break
  - 1 - 2 pm  Taxonomy explanation + assign your sequences. If time permits, make a phyloseq object
  - 2 - 4 pm on wards we will use a real world dataset to re-do what we have learned here


## Important links

- DADA2 Tutorial :  [link](http://benjjneb.github.io/dada2/tutorial.html)
- Day One presentation : [link](microbiomeworkshop.pdf)
- Day One dataset : [link](MiSeqSOPData.zip)
- Project dataset : [link](https://www.dropbox.com/sh/qra6ohbsyt1icaz/AAACvlNjUhfkbkGIp_1KA2uCa?dl=0)

<!--chapter:end:index.Rmd-->


# Basic Information

We are very excited to teach this workshop and share what we know with you all !

So lets start by talking about the very basics:


## What are we trying to achieve

Our goal is very similar to gathering data on a city neighbourhood to find out who lives there, how the demographic changes over time  or in case of a drastic event. We can gather more information by asking about neighbours, quality of life etc. Similarly when we are looking at microbial communities our first question is who is there, how abundant and how their presence changes over time or when conditions change. We can also ask questions like how the microbiomes are interacting with each other (metabolites).

  <p><font color="Tomato">For the scope of this workshop we will stick to the simple questions: who and how much?</p></font>


<br>

## Basics & Background

Here is the link to the lecture we will  start with today: [workshop](microbiomeworkshop.pdf)

Key points are:

- Think of a hypothesis before doing an experiment
- Spend time on experiment design.
  - Sample size, 16s region to amplify etc
  - Talk to a bioinformatician
  - Think about the depth of sequencing if you want to capture the less abundant taxa
  - Add negative control to account for contamination

- Thoughtful data analysis is critical for successful identification of microbes

<p><font color="Tomato">"If you torture the data long enough, it will confess."- Ronald Coase, Economist </p></font>




<!--chapter:end:02-Introduction.Rmd-->


# Primer Removal
There are multiple ways in which you can remove primers sequences from your fastq files. 
[CutAdapt](https://cutadapt.readthedocs.io/en/stable/index.html)  and [trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) are two widely used tools for short-read data. DADA2 package has its own removePrimers sequence function which is recommended for PacBio data.



## CutAdapt

The first step that everyone performs before doing an analysis is data cleaning. Data cleaning can mean multiple things in this context: primer removal, quality trimming, removing very short sequences etc. Remember inconsistent and incorrect data leads to false conclusions. In short, garbage in, garbage out applies to all data.

The first step that we will do with amplicon data is check which 16s rRNA gene region was sequenced, find the primer that were used and remove them. For this purpose there are a few software available like, cutAdapt, Trimmomatic, skewer. For the purpose of this workshop we will use cutAdapt.

Cutadapt finds and removes adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads. It also alows you to perform quality trimming on your reads.

### Primer removal for paired end reads

<pre>
cutadapt -a ADAPTER_FWD -A ADAPTER_REV -o out.1.fastq -p out.2.fastq reads.1.fastq reads.2.fastq
</pre>

Here, the input reads are in reads.1.fastq and reads.2.fastq, and the result will be written to out.1.fastq and out.2.fastq.

In paired-end mode, the options -a, -b, -g and -u that also exist in single-end mode are applied to the forward reads only. To modify the reverse read, these options have uppercase versions -A, -B, -G and -U that work just like their counterparts. In the example above, ADAPTER_FWD will therefore be trimmed from the forward reads and ADAPTER_REV from the reverse reads.


Single-end/R1 option	| Corresponding option for R2
----------|----------
--adapter, -a	|-A
--front, -g	|-G
--anywhere, -b	| -B
--cut, -u	| -U
--output, -o |	--paired-output, -p

In paired-end mode, Cutadapt checks whether the input files are properly paired. An error is raised if one of the files contains more reads than the other or if the read names in the two files do not match. The read name comparison ignores a trailing /1 or /2 to allow processing some old Illumina paired-end files.


Cutadapt supports compressed input and output files. Whether an input file needs to be decompressed or an output file needs to be compressed is detected automatically by inspecting the file name: For example, if it ends in .gz, then gzip compression is assumed

### Quality trimming

<pre>
cutadapt -q 15,10 -o out.1.fastq -p out.2.fastq reads.1.fastq reads.2.fastq
</pre>
-q 15,10


### Call cutAdapt from R

Follow this link to see how you can call cutAdapt from within R
https://benjjneb.github.io/dada2/ITS_workflow.html






<!--chapter:end:03-Primer_removal.Rmd-->


# DADA2


## DADA2 pipeline (v1.2)

From now on, we will be working on the DADA2 package version 1.12. DADA2 has great documentation and an excellent tutorial online.Please go to the following link http://benjjneb.github.io/dada2/tutorial.html

All the notes from now on are my additional comments to help you follow the pipeline:

### Data for the tutorial

The data to use for the tutorial can be downloaded from [here](MiSeqSOPData.zip)

### Getting ready ( load packages and get file list)

Functions that we will be using here are :

- list.files()
- sort()
- strsplit()
- basename()
- sapply()

### Inspect read quality profiles

Read in files

```{r,readdata}
library(dada2);
library(limma)
path <- "MiSeq_SOP/"
list.files(path)
```



```{r, findsamplenames}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq


tmp<-strsplit(basename(fnFs), "_")


# As tmp is a list of vectors, we will have to use sapply function to get the first position out from each vector. The symbol '[' tells sapplly function that it is a vector and 1 specifies the vector index

samples.names<-sapply(tmp,'[',1)

```


### Lets make plots to look at the quality for multiple files


```{r, make_plots}

plotQualityProfile(fnFs[1:2])

joint_fnames<-c(rbind(fnFs,fnRs))

plotQualityProfile(joint_fnames)

num=ceiling(length(joint_fnames)/6)

for(i in 1: num)

{
  plotQualityProfile(joint_fnames[i:i+5])


}



```

<!--chapter:end:04-DADA2.Rmd-->

# Day Two

## Main concepts to be discussed:
- Finish dada2 pipeline
- Assign Taxonomy
- Intro to Phyolseq package
- Create a Phylum level bar plots
- Alpha diversity plots
- Beta diversity plots


Once we are finished using the dada2 package, we will have a sequence table and taxonomy table.

Lets look at the metadata files we have to get more information about these samples.

```{r,metadata}

library(ggplot2)
library(dplyr)
time_info<-read.delim("~/projects/16sanalysis_workshop/workshoptutorial/MiSeq_SOP/mouse.time.design",sep  = "\t")
dpw_info<-read.delim("~/projects/16sanalysis_workshop/workshoptutorial/MiSeq_SOP/mouse.dpw.metadata",sep  = "\t")

sample_info<-left_join(time_info,dpw_info,by="group")

rownames(sample_info)<- sample_info$group

sample_info
```

Lets make a phyloseq object

```{r}




```

Now that we have sample_info lets try to make a phyloseq object out of this

```{r, phyloseq}
library(phyloseq)
taxa<-readRDS("~/projects/16sanalysis_workshop/workshoptutorial/output/taxa.rds")
seq<-readRDS("~/projects/16sanalysis_workshop/workshoptutorial/output/seq.rds")

ps <- phyloseq(otu_table(seq,taxa_are_rows = F),
               sample_data(sample_info),
               tax_table(taxa))

ps
```

You can see that this object has an OTU table(ASV table), sample data and tax_table. You can use functions tax_table(), sample_data() and otu_table() to access the data.

Take a look at:

- subset_samples()
- subset_taxa()
- tax_glom()
- sample_sums()
- prune_samples()
- transform_sample_counts()
- psmelt()



```{r}
ps2<-tax_glom(ps,taxrank = "Phylum")
ps2 = transform_sample_counts(ps2, function(x) x/sum(x))
pmelt<-psmelt(ps2) %>% arrange(desc(Abundance))

cutoff<-0.005
pmelt_filt<-pmelt %>% group_by(Phylum,time) %>% filter(sum(Abundance) >cutoff)

ggplot(pmelt_filt,aes(x=Sample,y=Abundance,color=Phylum,fill=Phylum)) +geom_bar(stat = "identity")

pmelt_filt %>% group_by(time,Phylum) %>% summarise(mean_Abundance=mean(Abundance)) %>% ggplot(.,aes(x=time,y=mean_Abundance,fill=Phylum)) +geom_bar(stat="identity")

```

Figure out how to change the colors to custom colors!!

```{r, summary}


pmelt_filt %>% group_by(time,Phylum) %>% summarise(mean=mean(Abundance))

```


## Alpha & beta Diversity




```{r, alpha diversit,echo=F, warning=F}

richness<-estimate_richness(ps)
richness$time<-ps@sam_data$time

ggplot(richness,aes(x=time,y=Shannon,color=time)) + geom_boxplot() +geom_jitter()

```

```{r,echo=F}
ps %>%
transform_sample_counts(., function(x) log(1 + x)) %>%
plot_ordination(., ordinate(., method="PCoA", distance="bray"),
color="time" ,title="Bray NMDS")+ scale_colour_manual(values=(c("tomato","blue"))) + geom_point()#%>% #+ theme_bw()

#ps%>%
ord<-ordinate(ps,method = "PCoA",distance = "bray")

plot_ordination(ps,ordination = ord,color="time")

```

<!--chapter:end:05-Phyloseq.Rmd-->

# Summary


<!--chapter:end:06-Project.Rmd-->


# What Next?

<!--chapter:end:07-What_to_learn_next.Rmd-->

